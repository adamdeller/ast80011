# GI Simulator Batch runner
NOTE: This has so far been tested only under Linux! Windows and Mac users will need to adapt these instructions as appropriate.

To get started, you will need co create a virtual environment called .venv, like so:
'python3 -m venv .venv'
(or alternatively 'python -m venv .venv' , depending on your system.
You will need to change the 'shebang line' (first line) of the script gi_batchrun.py if your system's Python interpreter has a different name (e.g. python instead of python3))

Next, activate the virtual environment (i.e. with 'source .venv/bin/activate').

You will then need to install the required dependencies with:
'pip install -r requirements.txt'

After setup has been completed, run 'gi_batchrun.py' with the '--help' command line for a list of supported command line paremeters.

The --jobs parameter expects a directory containing the following structure:
/
---/1/galaxy1.json
---/1/galaxy2.json
---/1/interact.json
---/1/merge.json
---/1/plot1.json
---/1/plot2.json
---/1/plot3.json (arbitrary number of plot(x).json files supported)
---/2/galaxy1.json
---/2/galaxy2.json
---/2/interact.json
---/2/merge.json
---/2/plot1.json
---/2/plot2.json
---/2/plot3.json (arbitrary number of plot(x).json files supported)
---etc--

The names of each job sub-directory can be arbitrarily chosen. Numbers have been used here for simplicity.

The job sub-folders can be generated by an appropriate generator script if you need to run a large number of permuations.

The script will automatically detect whether relevant changes to parameters have been made between jobs, and skip re-running steps if appropriate.

# Known issues
DO NOT attempt to simultaneously run more than one instance of this script using the same 'model numbers' (i.e. as specified with --models), or they will interfere with each other and result in 'undefined behaviour'!!! (i.e. errors and/or incorrect results!)

The web server may occasionally hang and eventually respond with an error such as '502 Bad Gateway'.
This will cause the script to exit with an exception. If this happens, just re-run the script and it should be able to resume from the job folder that failed (it will however need to restart that entire job).
If partial output had already been downloaded, you will need to delete the output folder for such
partially-downloaded jobs prior to re-running the script, or those jobs will be skipped!
